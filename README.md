# Konkurs Bitgrit 2025 ‚Äì README

## üìÅ U≈ºywane pliki danych

- `train.csv` ‚Äì zbi√≥r treningowy dostarczony przez organizatora
- `test.csv` ‚Äì zbi√≥r testowy dostarczony przez organizatora

---

## üõ†Ô∏è Przetwarzanie danych

1. Wczytanie danych za pomocƒÖ pandas.
2. Zakodowanie kolumn kategorycznych (je≈õli u≈ºyty model nie obs≈Çuguje kategorii natywnie).
3. In≈ºynieria cech:
   - Konwersja kolumn typu "date" do warto≈õci liczbowych
   - Grupowanie niskoczƒôstotliwo≈õciowych kategorii
   - Standaryzacja warto≈õci numerycznych (je≈õli wymagane)
4. Podzia≈Ç na `X_train`, `y_train`, `X_test`

---

## üß† U≈ºyty algorytm

Model: `StackingClassifier`

Sk≈Çad:
- `CatBoostClassifier`
- `LGBMClassifier`
- `XGBClassifier`

Model ko≈Ñcowy (meta-model): `LogisticRegression`

Hiperparametry:
- `LogisticRegression`: {
  "penalty": 'l2',
  "C": 3e-2,
  "class_weight": 'balanced',
  "tol": 1e-4,
  "warm_start": False,
  "solver": 'lbfgs',
  "max_iter": 80,
  "random_state": 42,
  "multi_class": 'multinomial'
}
- `LGBMClassifier`: {
  "boosting_type": gbdt,
  "class_weight": None,
  "colsample_bytree": 0.9333584928887282,
  "importance_type": split,
  "learning_rate": 0.23332896051177257,
  "max_depth": 12,
  "min_child_samples": 20,
  "min_child_weight": 0.001,
  "min_split_gain": 0.0,
  "n_estimators": 142,
  "n_jobs": -1,
  "num_leaves": 34,
  "objective": multiclass,
  "random_state": 81,
  "reg_alpha": 0.0,
  "reg_lambda": 1,
  "subsample": 0.9720591168744056,
  "subsample_for_bin": 200000,
  "subsample_freq": 0,
  "num_class": 3,
  "boosting": gbdt,
  "metric": None,
  "verbose": -1,
  "min_data_in_leaf": 6
}
- `XGBClassifier`: {
  "objective": multi:softprob,
  "base_score": None,
  "booster": None,
  "callbacks": None,
  "colsample_bylevel": None,
  "colsample_bynode": None,
  "colsample_bytree": None,
  "device": None,
  "early_stopping_rounds": None,
  "enable_categorical": True,
  "eval_metric": None,
  "feature_types": None,
  "feature_weights": None,
  "gamma": 0.6551776163530296,
  "grow_policy": None,
  "importance_type": None,
  "interaction_constraints": None,
  "learning_rate": 0.07315523763489679,
  "max_bin": 219,
  "max_cat_threshold": None,
  "max_cat_to_onehot": None,
  "max_delta_step": None,
  "max_depth": 10,
  "max_leaves": 23,
  "min_child_weight": None,
  "missing": nan,
  "monotone_constraints": None,
  "multi_strategy": None,
  "n_estimators": 118,
  "n_jobs": -1,
  "num_parallel_tree": None,
  "random_state": 42,
  "reg_alpha": 0.013705730913738874,
  "reg_lambda": 0.012219537217204616,
  "sampling_method": None,
  "scale_pos_weight": None,
  "subsample": 0.9988236950762315,
  "tree_method": hist,
  "validate_parameters": None,
  "verbosity": None,
  "use_label_encoder": None,
  "gpu_id": None,
  "predictor": None,
  "num_class": 3
}
- `CatBoostClassifier`: {
  "iterations": 137,
  "learning_rate": 0.10095947308778701,
  "depth": 7,
  "l2_leaf_reg": 0.01124311885824868,
  "loss_function": MultiClass,
  "random_seed": 42,
  "logging_level": Silent,
  "bagging_temperature": 1.0,
  "early_stopping_rounds": 3
}

U≈ºyto `stack_method="predict_proba"` i `cv=6`.

---

## üîÅ Jak odtworzyƒá rozwiƒÖzanie?

1. Zainstaluj wymagane biblioteki:
   ```bash
   pip install -r requirements.txt
   ```

2. Uruchom pipeline w odpowiedniej kolejno≈õci:

   a) Notebook do przetwarzania danych:
   ```bash
   jupyter notebook know_data.ipynb
   ```

   b) Notebook do trenowania modeli i generowania predykcji:
   ```bash
   jupyter notebook models.ipynb
   ```

   Notatniki:
   - WczytujƒÖ dane
   - PrzetwarzajƒÖ cechy i dane tekstowe
   - TrenujƒÖ modele
   - GenerujƒÖ plik predykcji `submission.csv`

---

## üß™ ≈örodowisko

- OS: Windows 11
- Python: 3.12
- RAM: 16 GB
- CPU: Intel i7-9700k
- GPU: (opcjonalnie) NVIDIA RTX 2080

---

## ‚ùì Pytania

- Jakie pliki sƒÖ u≈ºywane?
  - `train.csv`, `test.csv`
- Jak sƒÖ przetwarzane?
  - Przez notebook `know_data.ipynb`
- Algorytm i jego hiperparametry?
  - Opisano powy≈ºej
- Inne komentarze:
  - Ziarno losowe ustawione globalnie (`np.random.seed(42)`, `random_state=42`) dla powtarzalno≈õci wynik√≥w